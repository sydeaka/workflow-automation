f
f()
f()
################ Plot #5 ###########################################################
plot_age = function() {
rng = range(wd$DriverAge_years)
age1 = 20; age2 = 60
brks = c(rng[1], seq(age1, age2,5), rng[2])
age_labels = names(table(cut(wd$DriverAge_years, breaks=brks)))
age_labels = gsub('\\(|\\[|\\]', '', gsub(',', '-', age_labels))
age_labels[1] = paste('<=', age1)
age_labels[length(age_labels)] = paste(age2, '+')
make_plot = function() {
par(mar=c(3,2,2,2) + 0.1)
with(citation_by_age,
plot(as.numeric(age_group), pct_Citation, pch=19
, las=1, type='b' , xaxt = 'n'
, xlab = '' #'Age (years)'
, ylab='', main='Percent Issued Citation (%)'
)
)
mtext(text=age_labels, side=1, line=0, at=1:length(age_labels), cex=0.9)
mtext('Age (years)', side=1, line=1.5, at=mean(1:length(age_labels)))
}
return(make_plot())
}
plot_functions$plot_age = plot_age
plot_age()
plot_age()
plot_age()
################ Plot #5 ###########################################################
plot_age = function() {
rng = range(wd$DriverAge_years)
age1 = 20; age2 = 60
brks = c(rng[1], seq(age1, age2,5), rng[2])
age_labels = names(table(cut(wd$DriverAge_years, breaks=brks)))
age_labels = gsub('\\(|\\[|\\]', '', gsub(',', '-', age_labels))
age_labels[1] = paste('<=', age1)
age_labels[length(age_labels)] = paste(age2, '+')
#make_plot = function() {
par(mar=c(3,2,2,2) + 0.1)
with(citation_by_age,
plot(as.numeric(age_group), pct_Citation, pch=19
, las=1, type='b' , xaxt = 'n'
, xlab = '' #'Age (years)'
, ylab='', main='Percent Issued Citation (%)'
)
)
mtext(text=age_labels, side=1, line=0, at=1:length(age_labels), cex=0.9)
mtext('Age (years)', side=1, line=1.5, at=mean(1:length(age_labels)))
#}
#return(make_plot())
}
plot_functions$plot_age = plot_age
plot_age()
plot_age()
## Make plots (may have to render manually)
#source('plotly_plots.R')
#
View(summs)
## Load saved items
load('for_shiny.RData')
items = names(for_shiny)
for (item in items) assign(item, for_shiny[[item]])
rm(for_shiny,item,items)
shiny::runApp('Documents/korelasi/pdi/flash/R/Shiny/RacialBiasv0')
runApp('Documents/korelasi/pdi/flash/R/Shiny/RacialBiasv1')
names(plot_functions)
runApp('Documents/korelasi/pdi/flash/R/Shiny/RacialBiasv1')
runApp('Documents/korelasi/pdi/flash/R/Shiny/RacialBiasv1')
runApp('Documents/korelasi/pdi/flash/R/Shiny/RacialBiasv1')
runApp('Documents/korelasi/pdi/flash/R/Shiny/RacialBiasv1')
runApp('Documents/korelasi/pdi/flash/R/Shiny/RacialBiasv1')
runApp('Documents/korelasi/pdi/flash/R/Shiny/RacialBiasv1')
input$plot_type
runApp('Documents/korelasi/pdi/flash/R/Shiny/RacialBiasv1')
runApp('Documents/korelasi/pdi/flash/R/Shiny/RacialBiasv1')
runApp('Documents/korelasi/pdi/flash/R/Shiny/RacialBiasv1')
runApp('Documents/korelasi/pdi/flash/R/Shiny/RacialBiasv1')
runApp('Documents/korelasi/pdi/flash/R/Shiny/RacialBiasv1')
names(plot_functions)
runApp('Documents/korelasi/pdi/flash/R/Shiny/RacialBiasv1')
runApp('Documents/korelasi/pdi/flash/R/Shiny/RacialBiasv1')
runApp('Documents/korelasi/pdi/flash/R/Shiny/RacialBiasv1')
runApp('Documents/korelasi/pdi/flash/R/Shiny/RacialBiasv1')
runApp('Documents/korelasi/pdi/flash/R/Shiny/RacialBiasv1')
View(cluster_centers_with_summs)
runApp('Documents/korelasi/pdi/flash/R/Shiny/RacialBiasv1')
install.packages('DT')
runApp('Documents/korelasi/pdi/flash/R/Shiny/RacialBiasv1')
runApp('Documents/korelasi/pdi/flash/R/Shiny/RacialBiasv1')
runApp('Documents/korelasi/pdi/flash/R/Shiny/RacialBiasv1')
runApp('Documents/korelasi/pdi/flash/R/Shiny/RacialBiasv1')
?DT::formatRound
runApp('Documents/korelasi/pdi/flash/R/Shiny/RacialBiasv1')
runApp('Documents/korelasi/pdi/flash/R/Shiny/RacialBiasv1')
runApp('Documents/korelasi/pdi/flash/R/Shiny/RacialBiasv1')
closest_clusters = function(cluster_id) {
order(gower_mat[cluster_id,])
}
closest_clusters(1)
#
closest_clusters(1)
#closest_clusters(1)
#closest_clusters(1)
###
closest_clusters = function(cluster_id) {
order(gower_mat[cluster_id,])
} #closest_clusters(1)
knitr::opts_chunk$set(echo = TRUE)
#library(data.table)
library(rgdal)
library(leaflet)
library(rgeos)
library(sp)
(folders = list.files("../maps", full.names=T))
(folders = folders[grepl('pdf', folders) == F])
shape_files = sapply(folders, function(u) {
file = list.files(u, pattern='shp', full.names=T)
file = file[endsWith(x=file, suffix='.shp')]
return(file)
})
(shape_names = gsub('../maps/', '', folders))
(shape_names = gsub('Boundaries - ', '', shape_names))
read_shp = function(shape_file) {
shape <- readOGR(shape_file)
shape <- spTransform(shape, CRS("+proj=longlat +datum=WGS84 +no_defs"))
lbl = shape@data
return(list(shape=shape, lbl=lbl))
}
shape_objs = lapply(shape_files, read_shp)
names(shape_objs) = shape_names
lapply(shape_objs, function(u) head(u$lbl))
shape_objs[['Community Areas (current)']]$label_names = 'community'
shape_objs[['Police Beats (current)']]$label_names  = 'beat_num'
shape_objs[['Police Districts (current)']]$label_names  = 'dist_label'
shape_objs[['Wards (2015-)']]$label_names = 'ward'
shape_objs[['ZIP Codes']]$label_names = 'zip'
shape_objs[['Chicago Public Schools - High School Attendance Boundaries SY1516']]$label_names = 'schoolname'
shape_objs[['Chicago Public Schools - Middle School Attendance Boundaries SY1617']]$label_names = 'school_nm'
shape_objs[['City_Boundary']]$label_names = 'OBJECTID'
shape_objs[['CookCounty_Facilities']]$label_names = 'ANNO_NAME'
shape_objs[['Neighborhoods_2012']]$label_names = 'SEC_NEIGH'
shape_objs[['PoliceDistrict']]$label_names = 'DIST_LABEL'
shape_objs[['School_Grounds']]$label_names = 'SCHOOL_NAM'
shape_objs[['Forestry']]$label_names = 'NAME'
# (nm = shape_names[1])
get_centers = function(nm) {
obj = shape_objs[[nm]]
lbl = obj$lbl
lbl_name = obj$label_names
## Polygons
poly = attributes(obj$shape)$polygons
if (is.null(poly)) {
## Coordinates
centers = data.frame(lbl[lbl_name], attributes(obj$shape)$coords)
} else {
## Centers
centers = data.frame(lbl[lbl_name], t(sapply(poly, function(u) u@labpt)))
}
rownames(centers) = NULL
colnames(centers) = c('label', 'lng', 'lat')
return(centers)
} # end get_centers function
centers = lapply(shape_names, get_centers)
#centers = lapply(shape_names, get_centers)
for (i in shape_names) get_centers(i)
i
i
b = shape_objs$`Police Beats (current)`$shape
sapply(attributes(b)$polygons, function(u) u@area)
add_layer = function(nm, add_pop_ups=F) {
lbl = shape_objs[[nm]]$lbl
label_names = shape_objs[[nm]]$label_names
labels = as.character(unlist(lbl[label_names]))
lmp = leaflet()  %>% addTiles() %>%
setView(lng = -87.6298, lat=41.8781,zoom=11) %>%
addPolygons(data=shape_objs[[nm]]$shape, weight=5, col = 'blue', label=labels)
lmp
}
nm = 'Community Areas (current)'
add_layer(nm)
if (F) {
## Add pop-up markers
for (i in 1:nrow(centers)) {
lmp = lmp %>%
addMarkers(lng = centers$lng[i], lat=centers$lat[i], popup=centers$district[i])
}
}
shape_names
nm = "Police Districts (current)" #'Community Areas (current)'
add_layer(nm)
shape_files
shiny::runApp('Documents/korelasi/pdi/flash/R/Shiny/ITSSRacialBias')
require("knitr")
wd = "~/Projects/OPX/R"
opts_knit$set(root.dir = wd)
opts_chunk$set(echo = TRUE)
## Load libraries
suppressMessages(library(RJDBC))
#suppressMessages(library(getPass))
suppressMessages(library(plyr))
#suppressMessages(library(xlsx))
suppressMessages(library(data.table))
#suppressMessages(library(XLConnect))
suppressMessages(library(readxl))
#suppressMessages(library(RODBC))
## Helper functions
source("~/repos/on-premise-experts/IntelligenceScoring/Data Discovery/Table_Metadata_R_Solution/teradata_connection_helper_functions.R")
## Set parameters for database connections
username = system('echo $USER', intern=T)
teradata_driver_name = "com.teradata.jdbc.TeraDriver"
teradata_jar_files = c('terajdbc4.jar', 'tdgssconfig.jar')
driver_path = '/Users/sw659h/Tools/SQL/teradata_jars'
driver_name = list(aster="com.asterdata.ncluster.Driver", ecdw=teradata_driver_name, abs=teradata_driver_name, edw=teradata_driver_name)
jar_files = list(aster=c('noarch-aster-jdbc-driver.jar'), ecdw=teradata_jar_files, abs=teradata_jar_files, edw=teradata_jar_files)
class_path = list(aster="jdbc:ncluster://aster.it.att.com:2406/adwp", ecdw="jdbc:teradata://bhpm1.bhdc.att.com",
abs="jdbc:teradata://a7db.it.att.com", edw='jdbc:teradata://cnewp.sbc.com')
schema = list(aster='mktmraadhdb', ecdw=toupper(username), abs='', edw='')
get_paths = function(files) paste(paste(driver_path, files, sep='/'), collapse=':')
jar_paths = lapply(jar_files, get_paths)
conn_types = c('aster', 'ecdw', 'abs')
#conn_type = 'abs'
config = lapply(conn_types, function(conn_type) list(driver_name=driver_name[[conn_type]], jar_paths=jar_paths[[conn_type]], class_path=class_path[[conn_type]], schema=schema[[conn_type]]))
names(config) = conn_types
#config
cred_file = "/Users/sw659h/Tools/SQL/sw659h_upstart.txt"
ecdw = get_connection('ecdw', cred=cred_file)
## Utilities
mean0 = function(u) mean(u, na.rm=T)
sum0 = function(u) sum(u, na.rm=T)
positive = function(u) {
u = u[!is.na(u)]
sum(ifelse(u > 0, 1, 0))
}
pct = function(u) round(mean(u, na.rm=T) * 100,2)
## Set parameters
min_date = '201702'
run_time = 60
## Container to keep track of objects to be used in report
saved_objects = list()
## Read in the dataset
query = paste("select * from mktbciuatdb.es_dtv_dispatch_mobility_aci where appt_start_yearmo >= '", min_date, "';", sep='')
z = run_query(query)
colnames(z) = tolower(colnames(z))
z0 = z
z
saved_objects$z0 = z0
# paste(colnames(z), collapse="', '")
identifiers = c('cloc', 'ban')
segments = c('segment_dtv', 'segment_eng', 'segment_gas', 'segment_gv1', 'segment_gv2', 'segment_non', 'segment_rma', 'segment_sel', 'segment_sis', 'segment_unk', 'segment_null')
predictors_cat = c("appt_start_yearmo", 'state', "partner_name")
predictors_num = c("al_qty", "ls_dsl_qty", "dry_dsl_qty", "hsia_qty", "ipdslam_qty",              "iptv_qty", "voip_qty", "wrls_voice_qty", "wrls_data_qty", "wrls_vd_qty", 'rev_03mo', 'rev_12mo', 'cloc_3mo_dtv_rev', 'cloc_3mo_non_dtv_rev', 'cloc_ann_dtv_rev', 'cloc_ann_non_dtv_rev')
predictors_datetime = c('appt_start_mt_dt')
filter_vars = c('mobility_prev_1', 'mobility_curr')
mobility_outcome = c('mobility_curr', 'mobility_post_1', 'mobility_post_2', 'mobility_post_3', 'mobility_post_4', 'mobility_post_5', 'mobility_post_6', 'mobility_over_next_2', 'mobility_over_next_3', 'mobility_over_next_4', 'mobility_over_next_5', 'mobility_over_next_6' )
derived_outcome = 'cru_buy'
exclude_cols = c(identifiers, predictors_datetime, filter_vars, mobility_outcome)
z[,derived_outcome] = factor(ifelse(z$mobility_curr==0 & z$mobility_over_next_6 > 0, 1, 0))
(id_na = which(is.na(z$mobility_curr) | is.na(z$mobility_over_next_6)))
if (length(id_na) > 0) z[id_na, derived_outcome] = NA
vnames = unique(c(identifiers, segments, filter_vars, predictors_cat, predictors_num, predictors_datetime, mobility_outcome, derived_outcome))
saved_objects$columns_of_interest = list(identifiers=identifiers, segments=segments, filter_vars=filter_vars, predictors_cat=predictors_cat, predictors_num=predictors_num, predictors_datetime=predictors_datetime, mobility_outcome=mobility_outcome, derived_outcome=derived_outcome)
z = z[,vnames]
z = data.frame(z)
for (vname in c(identifiers,  predictors_cat)) z[,vname] = factor(z[,vname])
for (vname in unique(c(predictors_num, segments, mobility_outcome, filter_vars))) z[,vname] = as.numeric(z[,vname])
sapply(z, class)
z = data.table(z)
saved_objects$z = z
run_time = 30
cat(sapply(mobility_outcome, function(u) {
paste(u, ' = positive(', u, ')', sep='')
}), sep='\n,')
summ_mob_outcome = z[order(appt_start_yearmo), .(mobility_curr = positive(mobility_curr)
,mobility_post_1 = positive(mobility_post_1)
,mobility_post_2 = positive(mobility_post_2)
,mobility_post_3 = positive(mobility_post_3)
,mobility_post_4 = positive(mobility_post_4)
,mobility_post_5 = positive(mobility_post_5)
,mobility_post_6 = positive(mobility_post_6)
,mobility_over_next_2 = positive(mobility_over_next_2)
,mobility_over_next_3 = positive(mobility_over_next_3)
,mobility_over_next_4 = positive(mobility_over_next_4)
,mobility_over_next_5 = positive(mobility_over_next_5)
,mobility_over_next_6 = positive(mobility_over_next_6)
), by=appt_start_yearmo]
saved_objects$summ_mob_outcome = summ_mob_outcome
summ_mob_outcome
summ_mob_add = z[mobility_prev_1==0, .(.N,
mobility_curr = positive(mobility_curr)
,mobility_post_1 = positive(mobility_post_1)
,mobility_post_2 = positive(mobility_post_2)
,mobility_post_3 = positive(mobility_post_3)
,mobility_post_4 = positive(mobility_post_4)
,mobility_post_5 = positive(mobility_post_5)
,mobility_post_6 = positive(mobility_post_6)
,mobility_over_next_2 = positive(mobility_over_next_2)
,mobility_over_next_3 = positive(mobility_over_next_3)
,mobility_over_next_4 = positive(mobility_over_next_4)
,mobility_over_next_5 = positive(mobility_over_next_5)
,mobility_over_next_6 = positive(mobility_over_next_6)
), by=appt_start_yearmo][order(appt_start_yearmo)]
saved_objects$summ_mob_add = summ_mob_add
summ_mob_add
cat(sapply(segments, function(u) {
paste(u, ' = pct(', u, ')', sep='')
}), sep='\n,')
summ_segment = z[order(appt_start_yearmo), .(segment_dtv = pct(segment_dtv)
,segment_eng = pct(segment_eng)
,segment_gas = pct(segment_gas)
,segment_gv1 = pct(segment_gv1)
,segment_gv2 = pct(segment_gv2)
,segment_non = pct(segment_non)
,segment_rma = pct(segment_rma)
,segment_sel = pct(segment_sel)
,segment_sis = pct(segment_sis)
,segment_unk = pct(segment_unk)
,segment_null = pct(segment_null)
), by=appt_start_yearmo]
saved_objects$summ_segment = summ_segment
summ_segment
zm = z[,vnames[vnames %in% exclude_cols == F], with=F]
saved_objects$zm = zm
summary(zm)
library(h2o)
library(caret)
loadH2o = h2o.init(nthreads=6)
## Split into training/testing
the_seed = 12345
saved_objects$the_seed = the_seed
set.seed(the_seed)
vals  = unlist(zm[,derived_outcome, with=F]);# head(vals)
part = createDataPartition(y=vals, times=1, p=0.8)$Resample1
h2o_train = as.h2o(zm[part,])
remaining = zm[-part,]
vals  = unlist(remaining[,derived_outcome, with=F]); #head(vals)
part = createDataPartition(y=vals, times=1, p=0.5)$Resample1
h2o_test = as.h2o(remaining[part,])
h2o_valid = as.h2o(remaining[-part,])
sapply(list(h2o_train, h2o_valid, h2o_test), nrow) / nrow(zm)
pred_names = setdiff(names(h2o_train), derived_outcome)
## Utility to show performance metrics for h2o model
all_metrics = c('accuracy', 'fpr', 'fnr', 'tpr', 'tnr')
show_metrics = function(aml, metrics=NULL) {
best_model = aml@leader
lb <- as.data.frame(aml@leaderboard)
confusion = h2o.confusionMatrix(best_model)
perf = h2o.performance(best_model, valid=T)
(metrics = attributes(perf)$metrics$thresholds_and_metric_scores)
## Choose threshold with max f1 score in training set
id_max = which.max(metrics$f1)
(sel_metrics = round(unlist(metrics[id_max,]), 2))
rtn = list(confusion=confusion, sel_metrics=sel_metrics)
return(rtn)
}
## Utility to save individual models in AutoML
save_models = function(aml) {
(model_ids = as.vector(attributes(aml)$leaderboard$model_id))
#model_ids = model_ids[-grep('_model_', model_ids)]
obj_name = deparse(substitute(aml))
(new_path = paste('../h2o_results/models/', obj_name, sep=''))
suppressWarnings(dir.create(new_path))
cat('Saving models:\n')
for (id in model_ids) {
cat(id, '\n')
model = h2o.getModel(id)
h2o.saveModel(object=model, path=new_path, force=T)
}
cat('\n')
}
saved_objects$utilities = list()
saved_objects$utilities$show_metrics = show_metrics
saved_objects$utilities$save_models = save_models
saved_objects$automl = list()
## AutoML: using only default options
aml_default = h2o.automl(x=pred_names, y=derived_outcome, training_frame=h2o_train, leaderboard_frame=h2o_valid,
max_runtime_secs=run_time, exclude_algos='GLM')
#saved_objects$automl$aml_default = list(description='AutoML: using only default options', aml=aml_default)
saved_objects$automl$aml_default = list(description='AutoML: using only default options', aml=show_metrics(aml_default))
save_models(aml_default)
saved_objects$automl$aml_default
## AutoML: with balanced classes
aml_balanced_25_3 = h2o.automl(x=pred_names, y=derived_outcome, training_frame=h2o_train, leaderboard_frame=h2o_valid, max_runtime_secs=run_time, exclude_algos='GLM', balance_classes=T, class_sampling_factors=c(0.25,3))
saved_objects$automl$aml_balanced_25_3 = list(description='AutoML: with balanced classes, with sampling factors (0.25, 3)', aml=show_metrics(aml_balanced_25_3))
save_models(aml_balanced_25_3)
## AutoML: with balanced classes
aml_balanced_10_3 = h2o.automl(x=pred_names, y=derived_outcome, training_frame=h2o_train, leaderboard_frame=h2o_valid, max_runtime_secs=run_time, exclude_algos='GLM', balance_classes=T, class_sampling_factors=c(0.10,3))
saved_objects$automl$aml_balanced_10_3 = list(description='AutoML: with balanced classes, with sampling factors (0.10, 3)', aml=show_metrics(aml_balanced_10_3))
save_models(aml_balanced_10_3)
## AutoML: with balanced classes
aml_balanced_05_3 = h2o.automl(x=pred_names, y=derived_outcome, training_frame=h2o_train, leaderboard_frame=h2o_valid, max_runtime_secs=run_time, exclude_algos='GLM', balance_classes=T, class_sampling_factors=c(0.05,3))
saved_objects$automl$aml_balanced_05_3 = list(description='AutoML: with balanced classes, with sampling factors (0.05, 3)', aml=show_metrics(aml_balanced_05_3))
save_models(aml_balanced_05_3)
## Save objects
save(saved_objects, file='../h2o_results/objects/propensity_to_buy_modeling_objects.RData')
shiny::runApp('Documents/korelasi/pdi/flash/R/Shiny/ITSSRacialBias')
setwd("~/Documents/training/mysql/repos/workflow-automation/utils")
setwd('..')
infile_path='data/downloads'
sql_path='data/sql'
infile_name=csv_name
year='2016'
quarter=2
file_name = paste("LoanStats_", year, "Q", quarter, sep='')
csv_name = paste(file_name, ".csv", sep='')
table_name = paste('', file_name, sep='')
## Read in utility
source("utils/create_mysql_table.R")
infile_name=csv_name
mysql_db='lending',
mysql_db='lending'
mysql_table_name=table_name
mysql_file_name=gsub('csv', 'sql', paste('mysql_script_', csv_name, sep=''))
preview_size=100000
use_full_dataset=F
path_to_keytab=NULL
create_table=F
## File in local working directory, to be pushed into HDFS and Hive
path_to_file = paste(infile_path, infile_name, sep='/')
## Hive script (i.e., file to be created in this script) that creates the Hive table
mysql_file = paste(sql_path, mysql_file_name, sep='/')
## Get number of records
cmd = paste('cat ', path_to_file, '| wc -l')
(num_records = as.numeric(trimws(system(cmd, intern=T))) - 1)
## Read in the file: First pass on a subset to infer the data types
z = fread(path_to_file, strip.white=F, logical01=F, data.table=F, stringsAsFactors=F, #fill=T, comment.char = '#'
nrows=min(preview_size, num_records))
View(z)
?freod
library(data.table)
?freod
?fred
?fread
## Read in the file: First pass on a subset to infer the data types
z = fread(path_to_file, strip.white=F, logical01=F, data.table=F, stringsAsFactors=F, skip=1, #fill=T, comment.char = '#'
nrows=min(preview_size, num_records))
setwd("~/Documents/training/mysql/repos/workflow-automation/utils")
setwd("~/Documents/training/mysql/repos/workflow-automation/utils")
## Set session parameters
if (interactive()) {
year = 2017
quarter = 2
work_dir='/Users/sw659h/Documents/training/mysql'
} else {
## Read in parameters passed in as arguments
args = commandArgs(trailingOnly=TRUE)
year = args[1]
quarter = args[2]
work_dir = args[3]
}
## Container to hold objects/parameters to be saved for reporting
saved_objects = list()
saved_objects$parameters = list()
saved_objects$datasets = list()
saved_objects$automl = list()
saved_objects$descriptives = list()
## Set session parameters
if (interactive()) {
year = 2016
quarter = 2
work_dir='/Users/sw659h/Documents/training/mysql'
} else {
## Read in parameters passed in as arguments
args = commandArgs(trailingOnly=TRUE)
year = args[1]
quarter = args[2]
work_dir = args[3]
}
## Container to hold objects/parameters to be saved for reporting
saved_objects = list()
saved_objects$parameters = list()
saved_objects$datasets = list()
saved_objects$automl = list()
saved_objects$descriptives = list()
## Set session parameters
if (interactive()) {
year = 2016
quarter = 2
work_dir='/Users/sw659h/Documents/training/mysql/repos/workflow-automation'
} else {
## Read in parameters passed in as arguments
args = commandArgs(trailingOnly=TRUE)
year = args[1]
quarter = args[2]
work_dir = args[3]
}
## Container to hold objects/parameters to be saved for reporting
saved_objects = list()
saved_objects$parameters = list()
saved_objects$datasets = list()
saved_objects$automl = list()
saved_objects$descriptives = list()
## Set working directory, and set additional parameters
setwd(work_dir)
run_time = 180
saved_objects$parameters$run_time = run_time
saved_objects$parameters$year = year
saved_objects$parameters$quarter = quarter
## Load libraries
library(h2o)
library(lime)
library(caret)
## Function to Exit R session with informative message printed to console on exit
exitR = function(message_string) {
cat(message_string, '\nExiting R session.\n')
q()
}
## Look for dataset and data types files
data_file = paste('data/modeling_data/modeling_dataset_', year, '_Q', quarter, '.csv', sep='')
dtypes_file=paste('data/modeling_data/modeling_datatypes_', year, '_Q', quarter, '.csv', sep='')
if (!file.exists(data_file)) exitR(paste(data_file, 'does not exist.'))
